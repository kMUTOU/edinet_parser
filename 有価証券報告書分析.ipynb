{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 有価証券報告書の取得・分析処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kMUTOU/edinet_parser.git\n",
    "%cd ./edinet_parser/\n",
    "!pip install ipywidgets requests aiohttp pandas numpy xmltodict lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "import glob\n",
    "import sys\n",
    "import copy\n",
    "import zipfile\n",
    "import datetime as dt\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as plib\n",
    "import requests as req\n",
    "import xmltodict\n",
    "\n",
    "from lxml import etree\n",
    "import ipywidgets as widgets\n",
    "from edinet_api import Edinet\n",
    "\n",
    "from IPython.display import display as disp\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "dispmd = lambda txt: display_markdown(txt, raw=True)\n",
    "\n",
    "df_extract = pd.read_excel('./有価証券報告書XBRL抽出.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "def daterange(start_date: dt.date, end_date: dt.date) -> List[dt.date]:\n",
    "    '''\n",
    "    指定された開始日から終了日までの日付listを生成する関数\n",
    "    '''\n",
    "    dates: List[dt.date] = []\n",
    "    current_date = start_date\n",
    "    \n",
    "    # ループは終了日（end_date）を超えるまで継続\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date)\n",
    "        # 次の日付へ移動\n",
    "        current_date += dt.timedelta(days=1)\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Edinet APIの設定\n",
    "\n",
    "### 1.1 Subscription Keyの入力\n",
    "\n",
    "次のいずれかによって、Subscription Keyを設定する。\n",
    "1. 環境変数: `EDINET_API_KEY`を設定している\n",
    "2. `{\"Subscription-Key\": \"<KEY>\"}`と記載されたJSONファイルのパスを引数`key_path:str`に渡す。\n",
    "3. 1.及び2.でSubscriptionキーがない場合は、widgetsで入力を求める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = dt.date.today().isoformat()\n",
    "\n",
    "SOURCE_DIR = '.'\n",
    "\n",
    "edinet = Edinet(key_path='../edinet_api.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 書類一覧DBの作成\n",
    "\n",
    "EDINET APIは、二つのREST方式APIリクエストを提供しています。\n",
    "1. 書類一覧 API\n",
    "2. 書類取得 API\n",
    "\n",
    "1.の書類一覧 APIは、次の仕様により提供されており、日付別の書類一覧が取得できる。\n",
    "```Plain\n",
    "https://api.edinet-fsa.go.jp/api/[version]/documents.json?date=[ファイル日付]&type=[取得情報]&Subscription-Key=[API キー]\n",
    "```\n",
    "逆に言うと、日付別の書類一覧のみが提供されているため、提出者別の書類一覧などの情報をAPIから取得することはできない。このため、日付別の書類一覧を利用して、DBを構築して、抽出・選択の各種操作が可能となる様にする必要がある。\n",
    "\n",
    "ここでは、過去90日の書類一覧をそれぞれ取得し、pandasのDataFrameにした後に、featherフォーマットで保存する。featherフォーマットで保存されたファイルがあれば、ファイルの取得はスキップする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('documents_info.feather'):\n",
    "    # 開始日と終了日を定義\n",
    "    end_date = dt.date.today()\n",
    "    start_date = end_date  + dt.timedelta(days=-90)\n",
    "    date_list = [d.strftime('%Y-%m-%d') for d in daterange(start_date, end_date)]\n",
    "\n",
    "    # 非同期関数を使用して、効率的に書類一覧情報を取得する。\n",
    "    await edinet.async_get_docs(date_list)\n",
    "\n",
    "\n",
    "    # featherもしくはSQLite3でデータを保持する。\n",
    "    df_doc = pd.DataFrame()\n",
    "\n",
    "    BIT_COLUMNS = [\n",
    "        'withdrawalStatus',\n",
    "        'docInfoEditStatus',\n",
    "        'disclosureStatus',\n",
    "        'xbrlFlag',\n",
    "        'pdf_docFlag',\n",
    "        'attachDocFlag',\n",
    "        'englishDocFlag',\n",
    "        'csvFlag',\n",
    "        'legalStatus'\n",
    "    ]\n",
    "\n",
    "\n",
    "    paths = glob.glob(f'{edinet.TSV_PATH}/document_list_*.tsv.gz')\n",
    "    paths.sort()\n",
    "\n",
    "    for path in paths:\n",
    "        try:\n",
    "            df_tmp = pd.read_csv(path, sep='\\t', dtype=str)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f'{path}は空の書類一覧情報です', file=sys.stderr)\n",
    "        else:\n",
    "            print(f'{path}を読み込みました({len(df_tmp)}レコード)', file=sys.stdout)\n",
    "            df_doc = pd.concat([df_doc, df_tmp])\n",
    "\n",
    "\n",
    "    for col in ['periodStart', 'periodEnd']:\n",
    "        df_doc[col] = pd.to_datetime(df_doc[col], errors='coerce')\n",
    "        df_doc[col] = df_doc[col].dt.date\n",
    "\n",
    "    for col in ['opeDateTime', 'submitDateTime']:\n",
    "        df_doc[col] = pd.to_datetime(df_doc[col], errors='coerce')\n",
    "\n",
    "    for col in [col for col in df_doc.columns if 'Flag' in col]:\n",
    "        df_doc[col] = df_doc[col].astype(pd.Int8Dtype())\n",
    "\n",
    "    df_doc = df_doc.replace({np.nan: None, pd.NaT: None})\n",
    "    df_doc = df_doc.where(pd.notnull(df_doc), None)\n",
    "\n",
    "\n",
    "    cols = df_doc.select_dtypes('int8').columns\n",
    "    for col in cols:\n",
    "        df_doc[col] = df_doc[col].astype(str)\n",
    "\n",
    "    # sequenceNumberは不要\n",
    "    df_doc.drop(columns=['seqNumber'], inplace=True)\n",
    "\n",
    "    df_doc.to_feather('documents_info.feather')\n",
    "    disp(df_doc.head(10))\n",
    "\n",
    "else:\n",
    "    df_doc = pd.read_feather('documents_info.feather')\n",
    "    disp(df_doc.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 有価証券報告書XBRLデータ(zip)をAPIで取得し、ファイルを保存\n",
    "\n",
    "### 3.1 ipywdigetsで有価証券報告書提出者を選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filer_list = df_doc.loc[df_doc['docTypeCode'] == '120', 'filerName'].drop_duplicates().to_list()\n",
    "\n",
    "filer_widget = widgets.Combobox(\n",
    "    placeholder=\"提出者名\",\n",
    "    options=filer_list,\n",
    "    description=\"提出者名:\",\n",
    "    ensure_option=True,\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "def show_selected_filer(selected_filer):\n",
    "    dispmd(f'### 選択した提出者: {selected_filer}')\n",
    "\n",
    "\n",
    "ui = widgets.VBox([filer_widget])\n",
    "out = widgets.interactive_output(show_selected_filer,\n",
    "    {'selected_filer': filer_widget} \n",
    ")\n",
    "\n",
    "disp(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 取得すべき書類一覧を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込む有価証券報告書の条件をqueryに記述する。(docTypeCode: \"120\"が有価証券報告書)\n",
    "df_parse_target = df_doc.query(f'filerName == \"{filer_widget.value}\" & docTypeCode == \"120\"')\n",
    "disp(df_parse_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 書類のダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path, 'rb') as fr:\n",
    "        data = fr.read()\n",
    "    return data\n",
    "\n",
    "df_parse_target = df_parse_target[[\n",
    "    'docID', \n",
    "    'edinetCode', 'secCode', 'JCN', 'filerName', 'periodStart',\n",
    "    'periodEnd', 'submitDateTime'\n",
    "]]\n",
    "\n",
    "df_parse_target = df_parse_target.set_index('docID')\n",
    "df_parse_target['submitDateTime'] = pd.to_datetime(df_parse_target['submitDateTime'])\n",
    "df_parse_target['saveDir'] = df_parse_target['submitDateTime'].dt.strftime(f'{edinet.DOC_PATH}/%Y/%m')\n",
    "\n",
    "disp(df_parse_target)\n",
    "\n",
    "await edinet.get_documents(df_parse_target['saveDir'].to_dict())\n",
    "\n",
    "\n",
    "df_parse_target['xbrlPath'] = df_parse_target['saveDir'] + '/' + df_parse_target.index + '.zip'\n",
    "df_parse_target['XBRLFILE'] = df_parse_target['xbrlPath'].apply(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ダウンロードした書類(有価証券報告書)の読込・解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseXBRL(object):\n",
    "\n",
    "    def __init__(self, zip_data: io.BytesIO=None):\n",
    "        '''\n",
    "        '''\n",
    "        self.zip_data = zip_data\n",
    "        self.target_ns_dict = {}\n",
    "        self.content = None\n",
    "\n",
    "    @staticmethod\n",
    "    def __check(path):\n",
    "        '''\n",
    "        '''\n",
    "        if path is None:\n",
    "            return False\n",
    "\n",
    "        if not os.path.isfile(path):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "\n",
    "    def load_xbrl_from_zip(self, zip_data: io.BytesIO=None) -> bool:\n",
    "        '''\n",
    "        '''\n",
    "        self.zip_data = zip_data or self.zip_data \n",
    "\n",
    "        self.content = {}\n",
    "\n",
    "        try:\n",
    "            # ZIPファイルを開く\n",
    "            with zipfile.ZipFile(self.zip_data) as zip_ref:\n",
    "                # 読み込みたいファイル名\n",
    "                # 正規表現により、次の二つのみを書き出す。\n",
    "                # XBRL/PublicDoc/jpcrp030000-asr-[ddd]_[EDINETコード]-[ddd]_[決算日;%Y-%m-%d]_[提出日;%Y-%m-%d].xbrl\n",
    "                # XBRL/PublicDoc/jpcrp030000-asr-001_E23492-000_2024-09-30_01_2024-12-11_lab.xml'\n",
    "                files_list = [fn for fn in zip_ref.filelist if re.match(r'.*XBRL/PublicDoc/.*(\\.xbrl|_lab\\.xml)$', fn.filename)]\n",
    "\n",
    "                for fn in files_list:\n",
    "                    # ZIP内の指定ファイルを開いて読み込む\n",
    "                    ext = 'XBRL' if '.xbrl' in fn.filename else 'LABEL-XML'\n",
    "                    with zip_ref.open(fn) as file:\n",
    "                        content = file.read()  # ファイル内容をバイナリとして読み込む\n",
    "                        # text_content = content.decode('utf-8')  # 必要に応じてデコード（テキストファイルの場合）\n",
    "                        self.content.update({\n",
    "                            ext: content\n",
    "                        })\n",
    "            return True\n",
    "        except zipfile.BadZipFile:\n",
    "            print('Zip File may be collapsed.', file=sys.stderr)\n",
    "            return False\n",
    "\n",
    "\n",
    "    def parse_xbrl(self) -> tuple[pd.DataFrame, dict]:\n",
    "\n",
    "        # XBRLファイルを読み込み\n",
    "        if self.content is None:\n",
    "            with open(self.xbrl_path, 'rb') as file:\n",
    "                xbrl_data = etree.parse(file)\n",
    "        elif self.content.get('XBRL'):\n",
    "            xbrl_data = etree.parse(io.BytesIO(self.content.get('XBRL')))\n",
    "\n",
    "        # 勘定科目に基づく情報を抽出\n",
    "        data = []\n",
    "        root = xbrl_data.getroot()\n",
    "        target_ns_dict = {ns: url for ns, url in root.nsmap.items() if 'jp' in ns}\n",
    "        self.target_ns_dict = target_ns_dict\n",
    "\n",
    "        # 勘定科目 (例: AccountTitle) に基づき要素を取得\n",
    "        target_paths = ' | '.join([f'//{key}:*' for key in target_ns_dict.keys()])\n",
    "        ns_from_url = {url: ns for ns, url in target_ns_dict.items()}\n",
    "\n",
    "        for element in xbrl_data.xpath(target_paths, namespaces=root.nsmap):\n",
    "            # 科目\n",
    "            name_space = re.sub(r'{(.*)}.+', r'\\1', element.tag)\n",
    "            tag = element.tag.replace('{' + name_space + '}',  ns_from_url[name_space] + \":\")\n",
    "            # text\n",
    "            tag_value = element.text  # 残高\n",
    "\n",
    "            # element.attribで全ての属性が取得できる。\n",
    "            context_ref = element.get('contextRef')  # 対応するcontextRef\n",
    "            unit_ref = element.get('unitRef')  # 対応するunitRef\n",
    "            decimals = element.get('decimals')  # 対応するdecimals\n",
    "\n",
    "            # unit refが次のもので、decimalsが0以上の場合は、整数として処理する\n",
    "            if unit_ref in ['pure', 'JPY', 'JPYPerShares', 'shares']:\n",
    "                try:\n",
    "                    if '.' in tag_value:\n",
    "                        tag_value = float(tag_value)\n",
    "                    else:\n",
    "                        tag_value = int(tag_value)\n",
    "                except TypeError:\n",
    "                    tag_value = None\n",
    "            elif unit_ref is not None and unit_ref in ['pure', 'JPY', 'JPYPerShares', 'shares']:\n",
    "                raise ValueError(f'unknown unit_ref value = = {unit_ref}')\n",
    "\n",
    "            row = {\n",
    "                'tag': tag,\n",
    "                'value': tag_value,\n",
    "                'contextRef': context_ref,\n",
    "                'unitRef': unit_ref,\n",
    "                # 'decimals': decimals\n",
    "            }\n",
    "            if decimals:\n",
    "                row.update({'decimals': int(decimals)})\n",
    "\n",
    "            data.append(row)\n",
    "\n",
    "        return data, target_ns_dict\n",
    "\n",
    "\n",
    "    def get_label_ns(self) -> dict:\n",
    "\n",
    "        data_labels = {}\n",
    "\n",
    "        # elif self.content.get('XBRL'):\n",
    "        #     xbrl_data = etree.parse(io.BytesIO(self.content.get('LABEL-XML')))\n",
    "\n",
    "        for ns, url in self.target_ns_dict.items():\n",
    "            if 'cor' not in ns:\n",
    "                if not self.content['LABEL-XML']:\n",
    "                    path = f\"{self.xbrl_path.replace('.xbrl', '')}_lab.xml\"\n",
    "                    with open(path, 'r') as fr:\n",
    "                        dict_data = xmltodict.parse(fr.read())\n",
    "                else:\n",
    "                    dict_data = xmltodict.parse(io.BytesIO(self.content['LABEL-XML']))\n",
    "\n",
    "                data_labels.update({\n",
    "                    # f'{ns}:{label[\"@id\"].replace(\"label_\", \"\")}': f'{label[\"#text\"]}'\n",
    "                    # for label in dict_data['link:linkbase']['link:labelLink']['link:label']\n",
    "                    f'{ns}:{label[\"@xlink:label\"].replace(ns.replace('asr-001', 'asr') + '_', \"\").replace(\"_label\", \"\").replace(\"label_\", \"\")}': f'{label[\"#text\"]}'\n",
    "                    for label in dict_data['link:linkbase']['link:labelLink']['link:label']\n",
    "                })\n",
    "\n",
    "            else:\n",
    "\n",
    "                target_dir = os.sep.join(url.split('/')[3:])\n",
    "                space, target_date = url.split('/')[-3:-1]\n",
    "\n",
    "                # taxonomy path以下に対象となるディレクトリがなければ作成する\n",
    "                if not os.path.isdir(target_dir):\n",
    "                    #\n",
    "                    plib.Path(target_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "                    url = '/'.join(url.split('/')[:-1])\n",
    "                    url = f\"{url}/label/{space}_{target_date}_lab.xml\"\n",
    "\n",
    "                    # labelファイルを取得しtaxonomy pathに保存する。\n",
    "                    res = req.get(url)\n",
    "                    if res.status_code == 200:\n",
    "                        with open(f'{target_dir}/{space}_{target_date}_lab.xml', 'wb') as f:\n",
    "                            f.write(res.content)\n",
    "                    else:\n",
    "                        print(f'GET: {url}, STATUS CODE = {res.status_code}', file=sys.stderr)\n",
    "\n",
    "\n",
    "                if os.path.isfile(f'{target_dir}/{space}_{target_date}_lab.xml'):\n",
    "                    with open(f'{target_dir}/{space}_{target_date}_lab.xml', 'r') as f:\n",
    "                        # print(f'{target_dir}/{space}_{target_date}_lab.xml')\n",
    "                        dict_data = xmltodict.parse(f.read())\n",
    "                        data_labels.update({\n",
    "                            f'{ns}:{label[\"@id\"].replace(\"label_\", \"\")}': f'{label[\"#text\"]}'\n",
    "                            for label in dict_data['link:linkbase']['link:labelLink']['link:label']\n",
    "                        })\n",
    "\n",
    "        return data_labels\n",
    "\n",
    "\n",
    "def parse(data: io.BytesIO):\n",
    "\n",
    "    # if not os.path.isfile():\n",
    "    #     return None\n",
    "\n",
    "    xbrl = ParseXBRL(data)\n",
    "\n",
    "    # zipから必要となるXBRLファイルと_lab.xmlファイルを取得する。\n",
    "    ret = xbrl.load_xbrl_from_zip()\n",
    "\n",
    "    if not ret:\n",
    "        return None\n",
    "    elif xbrl.content == {}:\n",
    "        print('NO Valid XBRL Contents exist', file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    # XBRLファイルをパースする。\n",
    "    try:\n",
    "        data, ns = xbrl.parse_xbrl()\n",
    "    except:\n",
    "        print(f'Unknown Error', file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    # tagから日本語ラベル名を取得する\n",
    "    # print(f'target doc: {path}')\n",
    "    data_labels = xbrl.get_label_ns()\n",
    "\n",
    "    # pandas DataFrameに変換\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df['label'] = df['tag'].replace(data_labels)\n",
    "\n",
    "    ## 大株主の情報を取得する。\n",
    "    df_major_sh = df[df['contextRef'].str.contains(r\"CurrentYearInstant_No\\d{1,2}MajorShareholdersMember\", regex=True)][['contextRef', 'tag', 'value', 'label']]\n",
    "    if len(df_major_sh) > 0:\n",
    "        # ピボットして contextRef を行、tag を列に\n",
    "        df_pivot = df_major_sh.pivot(\n",
    "            index='contextRef',\n",
    "            columns='label',\n",
    "            values='value'\n",
    "        ).reset_index()\n",
    "\n",
    "        df_major_sh = df_pivot#.sort_values(\n",
    "        df_major_sh['contextRef'] = df_major_sh['contextRef'].str.replace(r'.*No(\\d{1,2}).*', r'\\1', regex=True).astype(np.int8)\n",
    "        df_major_sh = df_major_sh.sort_values(['contextRef'])\n",
    "\n",
    "    else:\n",
    "        df_major_sh = None\n",
    "\n",
    "\n",
    "    ## 子会社(Affiliated Entities)の情報\n",
    "    df_aes = pd.DataFrame()\n",
    "    target_tag = 'jpcrp_cor:OverviewOfAffiliatedEntitiesTextBlock'\n",
    "    try:\n",
    "\n",
    "        affiliated_entities = df.query(f'tag == \"{target_tag}\"')['value'].values[0]\n",
    "        df_aes = pd.read_html(io.StringIO(affiliated_entities), header=[0, 1])\n",
    "        df_aes = pd.concat(df_aes, axis='index')\n",
    "    except:\n",
    "        print(f'Not Found OverviewOfAffiliatedEntitiesTextBlock', file=sys.stderr)\n",
    "\n",
    "\n",
    "    # 連結・単体で必要となる項目が異なる。\n",
    "    # 連結決算ありは\"true\"、連結決算なしは\"false\"。\n",
    "    # 有価証券届出書、有価証券報告書、四半期報告書又は半期報告書以外の提出書類の場合及び経理の状況が記載されない場合は、nil。\n",
    "    try:\n",
    "        # consolidated => true/false\n",
    "        consolidated = df.query('tag == \"jpdei_cor:WhetherConsolidatedFinancialStatementsArePreparedDEI\"')['value'].values[0]\n",
    "        # \n",
    "        gaap = df.query('tag == \"jpdei_cor:AccountingStandardsDEI\"')['value'].values[0]\n",
    "        dispmd(f'### 会計基準: {gaap}({\"連結\" if consolidated == \"true\" else \"単体\"})')\n",
    "\n",
    "        df['unitRef'] = df['unitRef'].str.upper()\n",
    "        df.loc[df['unitRef'].isin(['JPY', 'PURE', 'JPYPERSHARES', 'SHARES']), 'value'] = pd.to_numeric(df.loc[df['unitRef'].isin(['JPY', 'PURE', 'JPYPERSHARES', 'SHARES']), 'value'])\n",
    "\n",
    "    except:\n",
    "        print(f'Not Found WhetherConsolidatedFinancialStatementsArePreparedDEI tag Error', file=sys.stderr)\n",
    "\n",
    "    if gaap == 'Japan GAAP':\n",
    "        target_tags = [\n",
    "            'jpcrp_cor:NetSalesSummaryOfBusinessResults', # 売上高、経営指標等\n",
    "            'jpcrp_cor:ProfitLossAttributableToOwnersOfParentSummaryOfBusinessResults', # 親会社株主に帰属する当期純利益又は親会社株主に帰属する当期純損失（△）、経営指標等\n",
    "            'jpcrp_cor:ComprehensiveIncomeSummaryOfBusinessResults', # 包括利益、経営指標等\n",
    "            'jpcrp_cor:RateOfReturnOnEquitySummaryOfBusinessResults', # 自己資本利益率、経営指標等\n",
    "            'jpcrp_cor:NetCashProvidedByUsedInOperatingActivitiesSummaryOfBusinessResults', # 営業活動によるキャッシュ・フロー、経営指標等\n",
    "            'jpcrp_cor:NetCashProvidedByUsedInInvestingActivitiesSummaryOfBusinessResults',\t# 投資活動によるキャッシュ・フロー、経営指標等\n",
    "            'jpcrp_cor:NetCashProvidedByUsedInFinancingActivitiesSummaryOfBusinessResults', # 財務活動によるキャッシュ・フロー、経営指標等\n",
    "            'jpcrp_cor:CashAndCashEquivalentsSummaryOfBusinessResults' # 現金及び現金同等物、経営指標等\n",
    "        ]\n",
    "    elif gaap == 'IFRS':\n",
    "        target_tags = [\n",
    "            # IFRS\n",
    "            'jpcrp_cor:RevenueIFRSSummaryOfBusinessResults', # 売上収益\n",
    "            'jpcrp_cor:ProfitLossAttributableToOwnersOfParentIFRSSummaryOfBusinessResults', # 当期利益又は当期損失（△）：親会社の所有者に帰属\n",
    "            'jpcrp_cor:EquityAttributableToOwnersOfParentIFRSSummaryOfBusinessResults', # 親会社の所有者に帰属する持分\n",
    "            'jpcrp_cor:TotalAssetsIFRSSummaryOfBusinessResults', # 総資産額\n",
    "            'jpcrp_cor:RateOfReturnOnEquityIFRSSummaryOfBusinessResults', # 自己資本利益率、経営指標等\n",
    "            'jpcrp_cor:RatioOfOwnersEquityToGrossAssetsIFRSSummaryOfBusinessResults', # IFRSの場合の自己資本比率\n",
    "\n",
    "            # 株価収益率は、連結・単体にも記載があったがどちらを利用すればいいかわからない。\n",
    "            # jpcrp_cor:PriceEarningsRatioIFRSSummaryOfBusinessResults, 株価収益率\n",
    "            'jpcrp_cor:CashFlowsFromUsedInOperatingActivitiesIFRSSummaryOfBusinessResults', # 営業活動によるキャッシュ・フロー\n",
    "            'jpcrp_cor:CashFlowsFromUsedInInvestingActivitiesIFRSSummaryOfBusinessResults', # 投資活動によるキャッシュ・フロー\n",
    "            'jpcrp_cor:CashFlowsFromUsedInFinancingActivitiesIFRSSummaryOfBusinessResults', # 財務活動によるキャッシュ・フロー\n",
    "            'jpcrp_cor:CashAndCashEquivalentsIFRSSummaryOfBusinessResults' # 現金及び現金同等物\n",
    "        ]\n",
    "    elif gaap == 'US GAAP':\n",
    "        target_tags = [\n",
    "            'jpcrp_cor:RevenuesUSGAAPSummaryOfBusinessResults',\n",
    "            'jpcrp_cor:ProfitLossBeforeTaxUSGAAPSummaryOfBusinessResults',\n",
    "            'jpcrp_cor:NetIncomeLossAttributableToOwnersOfParentUSGAAPSummaryOfBusinessResults',\n",
    "            'jpcrp_cor:ComprehensiveIncomeAttributableToOwnersOfParentUSGAAPSummaryOfBusinessResults',\n",
    "            'jpcrp_cor:EquityAttributableToOwnersOfParentUSGAAPSummaryOfBusinessResults',\n",
    "            'jpcrp_cor:EquityIncludingPortionAttributableToNonControllingInterestUSGAAPSummaryOfBusinessResults',\n",
    "            'jpcrp_cor:PriceEarningsRatioUSGAAPSummaryOfBusinessResults',\n",
    "            \n",
    "            'jpcrp_cor:CashFlowsFromUsedInOperatingActivitiesUSGAAPSummaryOfBusinessResults',\n",
    "            'jpcrp_cor:CashFlowsFromUsedInInvestingActivitiesUSGAAPSummaryOfBusinessResults',\n",
    "            'jpcrp_cor:CashFlowsFromUsedInFinancingActivitiesUSGAAPSummaryOfBusinessResults',\n",
    "            'jpcrp_cor:CashAndCashEquivalentsUSGAAPSummaryOfBusinessResults',\n",
    "        ]\n",
    "    df_div = df.loc[df['tag'].isin(target_tags), \n",
    "                    [#'tag', \n",
    "                     'contextRef', 'label', 'value', 'unitRef', 'decimals']]\n",
    "    \n",
    "    df_div = df_div.query('~contextRef.str.contains(\"NonConsolidatedMember\")')\n",
    "\n",
    "    target_tags = [\n",
    "        ## 配当額\n",
    "        # 提出会社に記載される内容なので、NonConsolidatedMember\n",
    "        'jpcrp_cor:DividendPaidPerShareSummaryOfBusinessResults', # １株当たり配当額、経営指標等\n",
    "        'jpcrp_cor:InterimDividendPaidPerShareSummaryOfBusinessResults', # １株当たり中間配当額、経営指標等\n",
    "        'jpcrp_cor:PayoutRatioSummaryOfBusinessResults', # 配当性向、経営指標等\n",
    "        'jpcrp_cor:TotalShareholderReturn', # \n",
    "        'jpcrp_cor:TotalNumberOfIssuedSharesSummaryOfBusinessResults' # 発行済株式\n",
    "    ]\n",
    "\n",
    "    df_append = df.loc[df['tag'].isin(target_tags), \n",
    "                       ['contextRef', 'label', 'value', 'unitRef', 'decimals']]\n",
    "    \n",
    "    df_div = pd.concat([df_div, df_append], axis='index', ignore_index=True)\n",
    "\n",
    "    # df[df[['A', 'B']].apply(tuple, axis=1).isin(targets)]\n",
    "\n",
    "    df_div['contextRef'] = df_div['contextRef'].str.replace(r'(.*Year).*', r'\\1', regex=True)\n",
    "\n",
    "    df_div = df_div.pivot(\n",
    "        index='label',\n",
    "        columns='contextRef',\n",
    "        values='value'\n",
    "    ).reset_index()\n",
    "\n",
    "    df_add_info = {}\n",
    "    for tgt in ['CurrentYear', 'Prior1Year']:\n",
    "        df_extract_target = copy.copy(df_extract)\n",
    "        df_extract_target['contextRef'] = df_extract_target['contextRef'].str.replace('CurrentYear', tgt)\n",
    "        df_add_info[tgt] = df.merge(df_extract_target, how='inner', on=['contextRef', 'tag']).drop_duplicates()\n",
    "        df_add_info[tgt] = df_add_info[tgt].set_index(['output_label'])['value'].to_dict()\n",
    "    \n",
    "    return {\n",
    "        'major_shareholders': df_major_sh, \n",
    "        'frame': {\n",
    "            '指標': df_div,\n",
    "            '当期': df_add_info['CurrentYear'],\n",
    "            '前期': df_add_info['Prior1Year'], \n",
    "        },\n",
    "        'affiliated_entities': df_aes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = df_parse_target['XBRLFILE'].apply(lambda data: parse(io.BytesIO(data)))\n",
    "\n",
    "disp(ret[0]['major_shareholders'])\n",
    "disp(ret[0]['frame']['指標'])\n",
    "\n",
    "df_info = {}\n",
    "for tgt in ['当期', '前期']:\n",
    "    stock_info = {}\n",
    "    for row_num in range(len(df_parse_target)):\n",
    "        stock_info.update({\n",
    "            df_parse_target['periodEnd'][row_num].isoformat(): ret[row_num]['frame'][tgt]\n",
    "        })\n",
    "\n",
    "    df_tmp = pd.DataFrame(stock_info)\n",
    "    df_tmp = df_tmp.transpose()\n",
    "    df_tmp = df_tmp.fillna(0)\n",
    "    df_tmp.index = pd.to_datetime(df_tmp.index)\n",
    "    disp(df_tmp)\n",
    "    \n",
    "    df_info[tgt] = df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = {}\n",
    "for tgt in ['当期', '前期']:\n",
    "    stock_info = {}\n",
    "    for row_num in range(len(df_parse_target)):\n",
    "        stock_info.update({\n",
    "            df_parse_target['periodEnd'][row_num].isoformat(): ret[row_num]['frame'][tgt]\n",
    "        })\n",
    "\n",
    "    df_tmp = pd.DataFrame(stock_info)\n",
    "    df_tmp = df_tmp.transpose()\n",
    "    df_tmp = df_tmp.fillna(0)\n",
    "    df_tmp.index = pd.to_datetime(df_tmp.index)\n",
    "    # disp(df_tmp)\n",
    "    df_info[tgt] = df_tmp\n",
    "\n",
    "df_info = df_info['当期'].join(df_info['前期'], lsuffix='_当期', rsuffix='_前期')\n",
    "disp(df_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in ['当期', '前期']:\n",
    "    df_info[f'有利子負債_{term}'] = 0\n",
    "    for col in [f'短期借入金', '社債・借入金(流動)', '社債・借入金(固定)']:\n",
    "        if col + f'_{term}' in df_info.columns:\n",
    "            df_info[f'有利子負債_{term}'] += df_info[f'{col}_{term}']\n",
    "\n",
    "    df_info[f'投下資本_{term}'] = df_info[f'有利子負債_{term}'] + df_info[f'株主資本_{term}']\n",
    "    for col in [f'剰余金の配当']:\n",
    "        if col + f'_{term}' in df_info.columns:\n",
    "            df_info['配当性向'] = -df_info[f'{col}_{term}'] / df_info[f'親会社株主に帰属する当期純利益_{term}']\n",
    "\n",
    "df_info['RoE'] = df_info['親会社株主に帰属する当期純利益_当期'] / (df_info['株主資本_前期'] + df_info['株主資本_当期']) / 2 \n",
    "if '剰余金の配当_当期' in df_info.columns:\n",
    "    df_info['DoE'] = -df_info['剰余金の配当_当期']  / (df_info['株主資本_前期'] + df_info['株主資本_当期']) / 2 \n",
    "\n",
    "# Returnには、当期純利益(包括利益)を利用\n",
    "df_info['RoA'] = df_info['当期純利益_当期']  / (df_info['株主資本_前期'] + df_info['株主資本_当期']) / 2 \n",
    "\n",
    "df_info['RoIC'] = df_info['親会社株主に帰属する当期純利益_当期'] / (df_info['投下資本_前期'] + df_info['投下資本_当期']) / 2 \n",
    "\n",
    "disp(df_info[[#'従業員数(連結)', '従業員数(単体)', \n",
    "             '資本金_当期', '資本剰余金_当期', '利益剰余金_当期', '株主資本_当期', \n",
    "             '有利子負債_当期', \n",
    "             '投下資本_当期', \n",
    "             '親会社株主に帰属する当期純利益_当期', \n",
    "             'RoA', 'RoE', 'RoIC',              \n",
    "            #  '剰余金の配当_当期',\n",
    "            #  '配当性向', 'DoE'\n",
    "             ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RoE / RoIC推移の可視化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# 折れ線グラフを作成\n",
    "fig = px.line(df_info[['RoA', 'RoE', 'RoIC']], markers=True)\n",
    "fig.update_traces(\n",
    "    marker=dict(size=8, symbol=\"circle\"),\n",
    "    line=dict(width=2),\n",
    "    textposition=\"top center\"  # テキストの位置（上中央など）\n",
    ")\n",
    "\n",
    "# グラフを表示\n",
    "dispmd('### 収益指標(RoA / RoE / RoIC)')\n",
    "fig.show()\n",
    "\n",
    "# 折れ線グラフを作成\n",
    "fig = px.line(df_info[['RoA', 'RoE', 'RoIC']], markers=True)\n",
    "fig.update_traces(\n",
    "    marker=dict(size=8, symbol=\"circle\"),\n",
    "    line=dict(width=2),\n",
    "    textposition=\"top center\"  # テキストの位置（上中央など）\n",
    ")\n",
    "\n",
    "# グラフを表示\n",
    "dispmd('### 収益指標(RoA / RoE / RoIC)')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
